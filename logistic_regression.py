# -*- coding: utf-8 -*-
"""Logistic-Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tKxkCFsrjDQGwPEcL-wHe9BqygUCJOwY

# **4. Logistic Regression**

### **Problem Statement**  

Predict whether a customer will make a purchase (1: Yes, 0: No) using **Logistic Regression**.

---

### **Dataset Overview**  
DataSetLink: https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset
#### **Attributes**:  
1. **Age**: Customer's age (integer).  
2. **Gender**: Gender of the customer (0 = Male, 1 = Female).  
3. **Annual Income ($)**: Annual income of the customer in dollars.  
4. **Time Spent on Website**: Time spent by the customer on the website in minutes.  
5. **Loyalty Program**: Membership in loyalty program (0 = No, 1 = Yes).  
6. **Discounts Availed**: Number of discounts availed by the customer (0â€“5).  
7. **PurchaseStatus (Target Variable)**:  
   - 1: Customer made a purchase.  
   - 0: Customer did not make a purchase.  

---

### **Instructions**  

1. **Data Splitting**  
   - Split the dataset into training (80%) and testing (20%) sets.  

2. **Model Training**  
   - Train a Logistic Regression model on the training data.  

3. **Evaluation**  
   - Evaluate the model using the following metrics:  
     - **Confusion Matrix**  
     - **Precision, Recall, and F1-score**  
    
4. **Report Writing**  
   - Summarize model performance in terms of:  
     - Precision  
     - Recall  
     - F1-score  
     - Insights about which features contributed the most to the predictions.
"""

import pandas as pd

data = pd.read_csv("customer_purchase_data.csv")

print(data.head())

print("Missing values per column:\n", data.isnull().sum())

data = data.fillna(data.mean())

print(data.describe())

from sklearn.model_selection import train_test_split

X = data.drop(columns=["PurchaseStatus"])
y = data["PurchaseStatus"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training set size: {X_train.shape[0]}, Testing set size: {X_test.shape[0]}")

from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression(random_state=42)
logreg.fit(X_train, y_train)

y_pred = logreg.predict(X_test)
y_pred_proba = logreg.predict_proba(X_test)[:, 1]

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:")
print(cm)

from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-score: {f1:.2f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

coefficients = pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": logreg.coef_[0]
}).sort_values(by="Coefficient", ascending=False)

print("\nFeature Importance:")
print(coefficients)

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["No Purchase", "Purchase"], yticklabels=["No Purchase", "Purchase"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

plt.figure(figsize=(8, 6))
plt.barh(coefficients["Feature"], coefficients["Coefficient"], color="skyblue")
plt.xlabel("Coefficient Value")
plt.title("Feature Importance in Logistic Regression")
plt.gca().invert_yaxis()
plt.show()

